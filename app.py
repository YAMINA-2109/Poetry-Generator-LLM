# -*- coding: utf-8 -*-
"""app_streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bYuogiQ5u40sI8Ey6-bWJNsrqzUDY7mV
"""

!pip install streamlit transformers torch pyngrok

from google.colab import drive
drive.mount('/content/drive')

import json
config_data = json.load(open('config.json'))
HF_TOKEN = config_data['HF_TOKEN']

from huggingface_hub import login
login(token=HF_TOKEN)

from huggingface_hub import login
from google.colab import userdata

key = userdata.get('Mistral_7b_instruct_v3')

login(key)

!pip install rouge-score

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
# from nltk.translate.bleu_score import sentence_bleu
# from rouge_score import rouge_scorer
# import torch
# from sklearn.metrics.pairwise import cosine_similarity
# from sklearn.feature_extraction.text import TfidfVectorizer
# from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
# from rouge_score import rouge_scorer
# 
# # Custom styles
# st.set_page_config(
#     page_title="Poetry Generator",
#     page_icon="ðŸŒŸ",
#     layout="wide"
# )
# 
# # CSS for custom design
# st.markdown("""
#     <style>
#         .main {
#             background-color: #f5f5f5;
#         }
#         .stButton>button {
#             background-color: #4CAF50;
#             color: white;
#             font-size: 16px;
#             border-radius: 8px;
#             padding: 10px 20px;
#         }
#         .stTextInput>div>input {
#             border-radius: 8px;
#             border: 1px solid #4CAF50;
#         }
#         .stDownloadButton>button {
#             background-color: #007bff;
#             color: white;
#             font-size: 16px;
#             border-radius: 8px;
#             padding: 10px 20px;
#         }
#         .stFileUploader>div>label {
#             color: #4CAF50;
#             font-weight: bold;
#         }
#     </style>
# """, unsafe_allow_html=True)
# 
# @st.cache_resource
# def load_model(model_name):
#     if model_name in ["openai-community/gpt2", "EleutherAI/gpt-neo-2.7B"]:
#         model_path = model_name
#     else:
#         model_path = f"/content/drive/MyDrive/projet_Gen_ia/{model_name}"
# 
#     tokenizer = AutoTokenizer.from_pretrained(model_path)
#     model = AutoModelForCausalLM.from_pretrained(model_path, device_map="auto", torch_dtype=torch.float16)
# 
#     generator = pipeline("text-generation", model=model, tokenizer=tokenizer)
# 
#     return generator, tokenizer
# 
# 
# # List of available models
# models = {
#     "GPT-NeoX-20B": "gptneo20b_on_instruction_poems",
#     "GPT-2-FT": "gpt2_on_instruction_poems",
#     "LLaMA-3-8B": "llma3-8b_on_instruction_poems",
#     "Mistral 7B": "mistral7b_on_instruction_poems",
#     # "GPT-2 (Pretrained)": "openai-community/gpt2",  # Pretrained GPT-2
#     # "GPT-Neo-2.7B (Pretrained)": "EleutherAI/gpt-neo-2.7B"  # Pretrained GPT-Neo
# }
# 
# # Header Section
# st.title("ðŸŒŸ Poetry Generator & Evaluator")
# st.markdown("Create lyrical and evocative poems based on your themes and instructions. Evaluate performance using BLEU and ROUGE metrics.")
# 
# # Sidebar for model selection
# st.sidebar.title("âš™ï¸ Model Configuration")
# selected_model = st.sidebar.selectbox("Choose a model:", list(models.keys()))
# generator, tokenizer = load_model(models[selected_model])
# 
# # Tabs for Single Poem and Dataset Evaluation
# tab1, tab2 = st.tabs(["ðŸ“ Generate & Evaluate a Single Poem", "ðŸ“‚ Evaluate Poems on a Dataset"])
# 
# # Tab 1: Single Poem Generation
# with tab1:
#     st.header("Generate and Evaluate a Single Poem")
#     title = st.text_input("Poem Title", "The stars and love")
#     theme = st.text_area("Theme (separated by commas)", "Living, Death, Time, Relationships, Nature")
#     instruction = st.text_area("Instruction", "Write a poem that captures the essence of the title and explores the given themes.")
# 
#     # Generate the poem
#     if st.button("Generate a Poem"):
#         with st.spinner("Generating..."):
#             # Create the prompt
#             prompt = f"""
#                 ### Role: You are a poet who writes in a lyrical and evocative style.
#                 ### Title: {title}
#                 ### Theme: {theme}
#                 ### Task: {instruction}
# 
#                 Poem:
#             """
#             # Generate the poem
#             generated_poem = generator(prompt, max_length=300, temperature=0.7, num_return_sequences=1)
#             poem = generated_poem[0]["generated_text"].split("Poem:")[-1].strip()
# 
#             # Store the poem in session_state
#             st.session_state["poem"] = poem
# 
#             # Display the generated poem
#             st.success("Poem generated successfully!")
#             st.text_area("Generated Poem", value=poem, height=200)
# 
#     # Evaluation
#     # BLEU and ROUGE score evaluation for a single poem
#     st.subheader("Evaluate the generated poem")
#     reference_poem = st.text_area("Enter a reference poem to evaluate the scores", "Reference for evaluating the poem.")
# 
#     if st.button("Calculate Scores"):
#         if "poem" not in st.session_state or not st.session_state["poem"]:
#             st.error("No generated poem found! Please generate a poem first.")
#         else:
#             with st.spinner("Calculating metrics..."):
#                 # Get the poem from session_state
#                 poem = st.session_state["poem"]
# 
#                 # Calculate BLEU and ROUGE scores
#                 bleu_score = sentence_bleu([reference_poem.split()], poem.split())
#                 scorer = rouge_scorer.RougeScorer(["rouge1", "rouge2", "rougeL"], use_stemmer=True)
#                 rouge_scores = scorer.score(reference_poem, poem)
# 
#                 # Display the results
#                 st.markdown(f"**BLEU Score:** {bleu_score:.4f}")
#                 st.markdown(f"**ROUGE-1:** {rouge_scores['rouge1'].fmeasure:.4f}")
#                 st.markdown(f"**ROUGE-2:** {rouge_scores['rouge2'].fmeasure:.4f}")
#                 st.markdown(f"**ROUGE-L:** {rouge_scores['rougeL'].fmeasure:.4f}")
# # Tab 2: Dataset Evaluation
# with tab2:
#     st.header("Evaluate Poems on a Dataset")
#     uploaded_file = st.file_uploader("Upload a CSV File (Columns: title, theme, instruction, reference_poem)", type=["csv"])
# 
#     if uploaded_file:
#         dataset = pd.read_csv(uploaded_file)
#         dataset["generated_poem"] = ""
#         st.write("Dataset loaded successfully. Here are the first 5 rows:")
#         st.dataframe(dataset.head())
#         st.write(f"Dataset shape: {dataset.shape}")
# 
#         # VÃ©rifier les colonnes requises
#         required_columns = {"Title", "Tags", "Poem"}
#         missing_columns = required_columns - set(dataset.columns)
# 
#         if missing_columns:
#             st.error(f"The dataset is missing the following required columns: {', '.join(missing_columns)}")
#         else:
#             if st.button("Generate and Evaluate on Dataset"):
#                 with st.spinner("Processing dataset..."):
#                     generated_poems = []
#                     bleu_scores = []
#                     rouge1_scores = []
#                     rouge2_scores = []
#                     rougeL_scores = []
# 
#                     for index, row in dataset.iterrows():
#                         prompt = f"""
#                             ### Role: You are a poet who writes in a lyrical and evocative style.
#                             ### Title: {row['Title']}
#                             ### Theme: {row['Tags']}
#                             ### Task: Write a poem that captures the essence of the title and explores the given themes.
# 
#                             Poem:
#                         """
#                         generated = generator(prompt, max_length=300, temperature=0.7, num_return_sequences=1)
# 
#                         # Extraire le poÃ¨me gÃ©nÃ©rÃ©
#                         generated_poem = generated[0]["generated_text"].split("Poem:")[-1].strip()
#                         dataset.at[index, "generated_poem"] = generated_poem
#                         # Stocker dans le dataset
# 
#                         generated_poems.append(generated_poem)
# 
#                         # Calcul des mÃ©triques BLEU et ROUGE
#                         bleu = sentence_bleu([row['Poem'].split()], generated_poem.split())
#                         scorer = rouge_scorer.RougeScorer(["rouge1", "rouge2", "rougeL"], use_stemmer=True)
#                         rouge_scores = scorer.score(row['Poem'], generated_poem)
# 
#                         bleu_scores.append(bleu)
#                         rouge1_scores.append(rouge_scores['rouge1'].fmeasure)
#                         rouge2_scores.append(rouge_scores['rouge2'].fmeasure)
#                         rougeL_scores.append(rouge_scores['rougeL'].fmeasure)
# 
#                     # predicted_poems = dataset["generated_poem"].fillna("")
#                     dataset["bleu_score"] = bleu_scores
#                     dataset["rouge1"] = rouge1_scores
#                     dataset["rouge2"] = rouge2_scores
#                     dataset["rougeL"] = rougeL_scores
# 
#                     # Ã‰valuer les poÃ¨mes gÃ©nÃ©rÃ©s
#                     reference_poems = dataset["Poem"].fillna("")
#                     predicted_poems = dataset["generated_poem"].fillna("")
# 
#                     # Calculer les scores ROUGE
#                     scorer = rouge_scorer.RougeScorer(["rouge1", "rouge2", "rougeL"], use_stemmer=True)
#                     rouge_scores = [
#                         scorer.score(pred, ref) for pred, ref in zip(predicted_poems, reference_poems)
#                     ]
#                     rouge1 = sum(score["rouge1"].fmeasure for score in rouge_scores) / len(rouge_scores)
#                     rouge2 = sum(score["rouge2"].fmeasure for score in rouge_scores) / len(rouge_scores)
#                     rougeL = sum(score["rougeL"].fmeasure for score in rouge_scores) / len(rouge_scores)
# 
#                     # Calculer la similaritÃ© cosinus
#                     vectorizer = TfidfVectorizer().fit(predicted_poems + reference_poems)
#                     tfidf_preds = vectorizer.transform(predicted_poems)
#                     tfidf_labels = vectorizer.transform(reference_poems)
#                     similarities = [
#                         cosine_similarity(tfidf_preds[i], tfidf_labels[i])[0][0]
#                         for i in range(len(predicted_poems))
#                     ]
#                     avg_similarity = sum(similarities) / len(similarities)
# 
#                     # Calculer les scores BLEU
#                     smoothing_function = SmoothingFunction().method1
#                     bleu_scores = [
#                         sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothing_function)
#                         for pred, ref in zip(predicted_poems, reference_poems)
#                     ]
#                     avg_bleu = sum(bleu_scores) / len(bleu_scores)
# 
#                     # Afficher les scores globaux
#                     st.success("Evaluation completed!")
#                     st.markdown(f"**ROUGE-1 (Average):** {rouge1:.4f}")
#                     st.markdown(f"**ROUGE-2 (Average):** {rouge2:.4f}")
#                     st.markdown(f"**ROUGE-L (Average):** {rougeL:.4f}")
#                     st.markdown(f"**BLEU (Average):** {avg_bleu:.4f}")
#                     st.markdown(f"**Cosine Similarity (Average):** {avg_similarity:.4f}")
# 
# 
#                     st.success("Evaluation completed!")
#                     st.dataframe(dataset.head())
# 
#                     st.download_button(
#                         label="Download Results as CSV",
#                         data=dataset.to_csv(index=False).encode("utf-8"),
#                         file_name="evaluation_results.csv",
#                         mime="text/csv"
#                     )

!ngrok authtoken 2s9lW3hioiAisUiiqhR0rhwwTQ9_72wgM9Rneusm5Do76fM5Y

from pyngrok import ngrok

# DÃ©marrer un tunnel HTTP sur le port 8501
public_url = ngrok.connect(8501, "http")
print(f"Votre application Streamlit est accessible Ã  cette URL : {public_url}")
# Lancer Streamlit
!streamlit run app.py --server.port 8501 >/dev/null 2>&1 &