# üöÄ Poetry Generator - Fine-Tuning et √âvaluation des Mod√®les LLM

Bienvenue dans ce projet de **g√©n√©ration de po√®mes** bas√© sur le **fine-tuning de mod√®les de langage**. Ce projet explore diff√©rentes architectures de mod√®les pour produire des po√®mes de haute qualit√© √† partir d'instructions donn√©es par l'utilisateur.

---

## üìå Objectifs du projet

- **Fine-tuner plusieurs mod√®les de langage** pour la g√©n√©ration de po√®mes.
- **Comparer les performances** des mod√®les en utilisant des m√©triques de qualit√© (BLEU, ROUGE, Cosine Similarity).
- **S√©lectionner le meilleur mod√®le** en fonction des performances obtenues.
- **D√©velopper une interface utilisateur interactive** permettant aux utilisateurs de g√©n√©rer des po√®mes en entrant un titre, un th√®me et des instructions sp√©cifiques.

---

## üõ†Ô∏è 1. Fine-Tuning et √âvaluation des Mod√®les

Nous avons test√© et compar√© **quatre mod√®les de langage** pour la g√©n√©ration de po√®mes :

1. **GPT-2 Fine-Tuned** 
2. **LLaMA-3-8B Fine-Tuned** 
3. **Mistral 7B Fine-Tuned** 
4. **GPT-NeoX-20B Fine-Tuned**

üìå **Tous les notebooks de fine-tuning sont disponibles dans le dossier `notebooks/` du d√©p√¥t.**

### **üîç √âtapes du Fine-Tuning :**

1. **Pr√©paration des donn√©es** : S√©lection et pr√©traitement d‚Äôun dataset de po√®mes (`checkai/instruction-poems`).
2. **Fine-tuning sur GPU** : Entra√Ænement sur Google Colab et stockage sur Google Drive.
3. **√âvaluation des performances** : Calcul des scores BLEU, ROUGE et Cosine Similarity.
4. **Comparaison des r√©sultats** : S√©lection du mod√®le le plus performant pour l'application finale.

#### **üìä R√©sultats de l‚Äô√©valuation :**
## **1Ô∏è‚É£ Sur le dataset d'√©valuation (que le mod√®le a vu durant l'entra√Ænement) :** 

| Mod√®le | ROUGE-1 | ROUGE-2 | ROUGE-L | Cosine Similarity |
|--------|---------|---------|---------|------------------|
| GPT-2 Fine-Tuned | 0.8345 | 0.7342 | 0.8268 | 0.5457 |
| LLaMA-3-8B Fine-Tuned | 0.7895 | 0.6595 | 0.7802 | 0.6239 |
| GPT-NeoX-20B Fine-Tuned | 0.7002 | 0.4991 | 	0.6892 | 0.5245 |
| Mistral 7B Fine-Tuned | 0.7055 | 	0.5208 | 0.6934 | 0.6023 |
		

## **2Ô∏è‚É£ Sur le dataset de test (des donn√©es que le mod√®le n'a jamais vues) :** 

| Mod√®le | BLEU Score | ROUGE-1 | ROUGE-2 | ROUGE-L | Cosine Similarity |
|--------|-----------|---------|---------|---------|------------------|
| GPT-2 Fine-Tuned | 0.0222 | 0.2000 | 0.0486 | 0.1517 | 0.0029 |
| LLaMA-3-8B Fine-Tuned | 0.0138 |0.1531 | 0.0290 | 0.0970 | 0.1499 |
| GPT-NeoX-20B Fine-Tuned| - | - | - | - | - |
| Mistral 7B Fine-Tuned | 0.0034 | 0.0906 | 0.0178 | 0.0645 | 0.0866 |


üéØ **Le mod√®le ..... Fine-Tuned a √©t√© s√©lectionn√© pour l‚Äôapplication finale.**

üìå **D√©tails techniques :** Le fine-tuning a √©t√© effectu√© sur Google Colab avec `transformers`, `torch` et `datasets` et GPU `A100` est obligatoire.

---

## üì∑ Interface d'√âvaluation

Nous avons d√©velopp√© une **interface intuitive avec Streamlit** pour permettre :

- La **g√©n√©ration de po√®mes** bas√©s sur un th√®me et des instructions sp√©cifiques.
- L‚Äô**√©valuation automatique des r√©sultats** √† l‚Äôaide de m√©triques NLP.
- L‚Äô**exportation des r√©sultats** au format CSV.
- L‚Äôobjectif principal de cette interface est d'√©valuer et de comparer les mod√®les afin de s√©lectionner le plus performant.
- Dans la prochaine √©tape, nous d√©velopperons une application adapt√©e aux utilisateurs finaux, int√©grant le mod√®le choisi.
- 
Voici quelques images de notre interface ainsi que les r√©sultats obtenus lors de nos tests des mod√®les.
### **1Ô∏è‚É£ S√©lection du mod√®le et g√©n√©ration d'un po√®me**
![Interface compl√®te](images/interface_1_complete.PNG)

### **2Ô∏è‚É£ S√©lection du mod√®le et g√©n√©ration de po√®mes sur un ensemble de donn√©es (un dataset de plusieurs lignes)**
![Interface 2](images/interface_2.PNG)

### **3Ô∏è‚É£ Po√®me g√©n√©r√© avec Mistral 7B**
![Po√®me g√©n√©r√©](images/mistrale_generated_poeme_1.PNG)
![Po√®me score](images/mistrale_7b_1_poeme_results_scores.PNG)

### **4Ô∏è‚É£ Po√®me g√©n√©r√© avec LLaMA-3-8B**
![Po√®me g√©n√©r√©](images/poeme_llama_1.PNG)
![Po√®me score](images/1_poeme_score_llama_1.PNG)

### **5Ô∏è‚É£ Po√®me g√©n√©r√© avec GPT-2**
![Po√®me g√©n√©r√©](images/gpt_2_generated_poeme.PNG)

### **6Ô∏è‚É£ √âvaluation des scores BLEU et ROUGE pour LLaMA-3-8B sur un petit dataset de 50 lignes**
![R√©sultats d‚Äô√©valuation 1](images/resultats_llama_2.PNG)
![R√©sultats d‚Äô√©valuation 2](images/resultats_de_llama_1.PNG)

### **7Ô∏è‚É£ √âvaluation des scores BLEU et ROUGE pour Mistral 7B sur un petit dataset de 50 lignes**
![R√©sultats d‚Äô√©valuation](images/mistral_7b_resultats_2.PNG)
![R√©sultats d‚Äô√©valuation 2](images/miostral_7b_resultats_1.PNG)

### **8Ô∏è‚É£  √âvaluation des scores BLEU et ROUGE pour GPT-2 sur un petit dataset de 50 lignes**
![√âvaluation sur dataset](images/gpt_2_result_2.PNG)
![√âvaluation sur dataset](images/gpt2_scores_on_100_cols_1.PNG)

---

## üöÄ 2. Acc√®s Public aux Mod√®les Fine-Tun√©s

üîó **Les mod√®les fine-tun√©s sont h√©berg√©s sur Hugging Face et peuvent √™tre t√©l√©charg√©s ici :**

- [LLaMA-3-8B Fine-Tuned](https://huggingface.co/IAyamina/llama3-8b_on_instruction_poems)
- [Mistral 7B Fine-Tuned](https://huggingface.co/IAyamina/mistral7b_on_instruction_poems)
- [GPT-2 Fine-Tuned](https://huggingface.co/IAyamina/gpt2_on_instruction_poems)
- [GPT-NeoX-20B Fine-Tuned](https://huggingface.co/IAyamina/gptneo20b_on_instruction_poems)

‚úÖ **Solution :**

- T√©l√©chargez le mod√®le directement depuis Hugging Face.
- Utilisez-le avec **Hugging Face Transformers** dans vos scripts Python.
- Ex√©cutez les notebooks associ√©s pour **r√©entra√Æner** le mod√®le et modifier les hyperparam√®tres si n√©cessaire.

üí° **Attention :**

- **Mistral 7B et LLaMA-3-8B n√©cessitent une cl√© d‚Äôacc√®s**. Vous devez **demander l‚Äôacc√®s** sur Hugging Face pour pouvoir les utiliser.

### **üîß √âtapes pour utiliser un mod√®le fine-tun√© :**

1Ô∏è‚É£ **Chargez le mod√®le dans votre script Python :**

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "IAYamina/mistral7b_on_instruction_poems"  # Remplacez par le mod√®le souhait√©
model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
```

2Ô∏è‚É£ **G√©n√©rez un po√®me avec le mod√®le :**

```python
def generate_poem(prompt):
    inputs = tokenizer(prompt, return_tensors="pt")
    output = model.generate(**inputs, max_length=100)
    return tokenizer.decode(output[0], skip_special_tokens=True)

print(generate_poem("Un po√®me sur l'automne"))
```
3Ô∏è‚É£ **Si n√©cessaire, entra√Ænez √† nouveau le mod√®le avec les notebooks disponibles.**
---

## üöÄ 3. Lancer l'Application et Tester les Po√®mes

üí° **Attention :**
- Notre code est con√ßu pour √™tre ex√©cut√© sur **Google Colab**.
- Vous devez **poss√©der une cl√© d'authentification pour `pyngrok`** si vous souhaitez d√©ployer l'application de la m√™me mani√®re.
- Tous les fichiers n√©cessaires √† l'ex√©cution se trouvent dans `app.py`.

### **üîß √âtapes pour lancer l'application :**

1Ô∏è‚É£ **T√©l√©chargez les mod√®les et placez-les dans votre Google Drive** en v√©rifiant bien les chemins d'acc√®s.

2Ô∏è‚É£ **Installez les d√©pendances n√©cessaires (`streamlit`, `pyngrok`, etc.)** et assurez-vous de disposer d'un **GPU A100** pour l'ex√©cution optimale.

3Ô∏è‚É£ **Ajoutez vos cl√©s d'authentification et ex√©cutez `app.py` sur Google Colab**.

4Ô∏è‚É£ **Lancez l'application avec Streamlit et acc√©dez-y via un tunnel `ngrok`.**

üìå **Commande pour lancer l'application**
```bash
!streamlit run app.py --server.port 8501
```
---

## üìå Prochaines √âtapes

‚úÖ **Fine-tuning et √©valuation des mod√®les**<br>
‚úÖ **S√©lection du meilleur mod√®le - Mistral 7B Fine-Tuned**<br>


---

## ü§ù Contribuer

Si vous souhaitez contribuer √† ce projet :

1. **Forkez le d√©p√¥t**.
2. **Ajoutez vos am√©liorations** sur une nouvelle branche.
3. **Soumettez une Pull Request** avec une description d√©taill√©e de vos modifications.

N‚Äôh√©sitez pas √† poser vos questions ou signaler des probl√®mes via la section **Issues** sur GitHub.

**üîó Contact :** Pour toute question, contactez-moi directement via GitHub ou LinkedIn !

---

üî• **Merci d‚Äôavoir suivi ce projet et bonne exploration de la g√©n√©ration de po√©sie avec l‚ÄôIA !** üî•

