# ğŸš€ Poetry Generator - Fine-Tuning et Ã‰valuation des ModÃ¨les LLM

Bienvenue dans ce projet de **gÃ©nÃ©ration de poÃ¨mes** basÃ© sur le **fine-tuning de modÃ¨les de langage**. Ce projet explore diffÃ©rentes architectures de modÃ¨les pour produire des poÃ¨mes de haute qualitÃ© Ã  partir d'instructions donnÃ©es par l'utilisateur.

---

## ğŸ“Œ Objectifs du projet

- **Fine-tuner plusieurs modÃ¨les de langage** pour la gÃ©nÃ©ration de poÃ¨mes.
- **Comparer les performances** des modÃ¨les en utilisant des mÃ©triques de qualitÃ© (BLEU, ROUGE, Cosine Similarity).
- **SÃ©lectionner le meilleur modÃ¨le** en fonction des performances obtenues.
- **DÃ©velopper une interface utilisateur interactive** permettant aux utilisateurs de gÃ©nÃ©rer des poÃ¨mes en entrant un titre, un thÃ¨me et des instructions spÃ©cifiques.

---

## ğŸ› ï¸ 1. Fine-Tuning et Ã‰valuation des ModÃ¨les

Nous avons testÃ© et comparÃ© **quatre modÃ¨les de langage** pour la gÃ©nÃ©ration de poÃ¨mes :

1. **GPT-2 Fine-Tuned** 
2. **LLaMA-3-8B Fine-Tuned** 
3. **Mistral 7B Fine-Tuned** 
4. **GPT-NeoX-20B Fine-Tuned**

ğŸ“Œ **Tous les notebooks de fine-tuning sont disponibles dans le dossier `notebooks/` du dÃ©pÃ´t.**

### **ğŸ” Ã‰tapes du Fine-Tuning :**

1. **PrÃ©paration des donnÃ©es** : SÃ©lection et prÃ©traitement dâ€™un dataset de poÃ¨mes (`checkai/instruction-poems`).
2. **Fine-tuning sur GPU** : EntraÃ®nement sur Google Colab et stockage sur Google Drive.
3. **Ã‰valuation des performances** : Calcul des scores BLEU, ROUGE et Cosine Similarity.
4. **Comparaison des rÃ©sultats** : SÃ©lection du modÃ¨le le plus performant pour l'application finale.

#### **ğŸ“Š RÃ©sultats de lâ€™Ã©valuation :**

| ModÃ¨le | BLEU Score | ROUGE-1 | ROUGE-2 | ROUGE-L | Cosine Similarity |
|--------|-----------|---------|---------|---------|------------------|
| GPT-2 Fine-Tuned | 0.0222 | 0.2000 | 0.0486 | 0.1517 | 0.0029 |
| LLaMA-3-8B Fine-Tuned | 0.0051 | 0.2029 | 0.0228 | 0.1318 | 0.1898 |
| GPT-NeoX-20B (non fine-tunÃ©) | - | - | - | - | - |
| **Mistral 7B Fine-Tuned** | **0.0034** | **0.1684** | **0.0189** | **0.1113** | **0.1649** |

ğŸ¯ **Le modÃ¨le ..... Fine-Tuned a Ã©tÃ© sÃ©lectionnÃ© pour lâ€™application finale.**

ğŸ“Œ **DÃ©tails techniques :** Le fine-tuning a Ã©tÃ© effectuÃ© sur Google Colab avec `transformers`, `torch` et `datasets` et GPU `A100` est obligatoire.

---

## ğŸ“· Interface d'Ã‰valuation

Nous avons dÃ©veloppÃ© une **interface intuitive avec Streamlit** pour permettre :

- La **gÃ©nÃ©ration de poÃ¨mes** basÃ©s sur un thÃ¨me et des instructions spÃ©cifiques.
- Lâ€™**Ã©valuation automatique des rÃ©sultats** Ã  lâ€™aide de mÃ©triques NLP.
- Lâ€™**exportation des rÃ©sultats** au format CSV.
- Lâ€™objectif principal de cette interface est d'Ã©valuer et de comparer les modÃ¨les afin de sÃ©lectionner le plus performant.
- Dans la prochaine Ã©tape, nous dÃ©velopperons une application adaptÃ©e aux utilisateurs finaux, intÃ©grant le modÃ¨le choisi.
- 
Voici quelques images de notre interface ainsi que les rÃ©sultats obtenus lors de nos tests des modÃ¨les.
### **1ï¸âƒ£ SÃ©lection du modÃ¨le et gÃ©nÃ©ration d'un poÃ¨me**
![Interface complÃ¨te](images/interface_1_complete.PNG)

### **2ï¸âƒ£ SÃ©lection du modÃ¨le et gÃ©nÃ©ration de poÃ¨mes sur un ensemble de donnÃ©es (un dataset de plusieurs lignes)**
![Interface 2](images/interface_2.PNG)

### **3ï¸âƒ£ PoÃ¨me gÃ©nÃ©rÃ© avec Mistral 7B**
![PoÃ¨me gÃ©nÃ©rÃ©](images/mistrale_generated_poeme_1.PNG)
![PoÃ¨me score](images/mistrale_7b_1_poeme_results_scores.PNG)

### **4ï¸âƒ£ PoÃ¨me gÃ©nÃ©rÃ© avec LLaMA-3-8B**
![PoÃ¨me gÃ©nÃ©rÃ©](images/poeme_llama_1.PNG)
![PoÃ¨me score](images/1_poeme_score_llama_1.PNG)

### **5ï¸âƒ£ PoÃ¨me gÃ©nÃ©rÃ© avec GPT-2**
![PoÃ¨me gÃ©nÃ©rÃ©](images/gpt_2_generated_poeme.PNG)

### **6ï¸âƒ£ Ã‰valuation des scores BLEU et ROUGE pour LLaMA-3-8B sur un petit dataset de 50 lignes**
![RÃ©sultats dâ€™Ã©valuation 1](images/resultats_llama_2.PNG)
![RÃ©sultats dâ€™Ã©valuation 2](images/resultats_de_llama_1.PNG)

### **7ï¸âƒ£ Ã‰valuation des scores BLEU et ROUGE pour Mistral 7B sur un petit dataset de 50 lignes**
![RÃ©sultats dâ€™Ã©valuation](images/mistral_7b_resultats_2.PNG)
![RÃ©sultats dâ€™Ã©valuation 2](images/miostral_7b_resultats_1.PNG)

### **8ï¸âƒ£  Ã‰valuation des scores BLEU et ROUGE pour GPT-2 sur un petit dataset de 50 lignes**
![Ã‰valuation sur dataset](images/gpt_2_result_2.PNG)
![Ã‰valuation sur dataset](images/gpt2_scores_on_100_cols_1.PNG)

---

## ğŸš€ 2. AccÃ¨s Public au ModÃ¨le Fine-TunÃ©

ğŸ’¡ **ProblÃ¨me initial :** Les modÃ¨les fine-tunÃ©s Ã©taient stockÃ©s sur Google Drive, ce qui empÃªchait leur accÃ¨s public.

âœ… **Solution : HÃ©bergement sur Hugging Face Model Hub**

### **ğŸ“¦ HÃ©berger le modÃ¨le sur Hugging Face**
1. **Se connecter Ã  Hugging Face et uploader le modÃ¨le** :
```python
from huggingface_hub import login, upload_folder

login(token="TON_HF_TOKEN")
model_path = "/content/drive/MyDrive/mistral7b_on_instruction_poems"
repo_id = "ton-utilisateur/mistral7b_finetuned"
upload_folder(repo_id=repo_id, folder_path=model_path)
```

2. **Utiliser le modÃ¨le depuis nâ€™importe oÃ¹** :
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("ton-utilisateur/mistral7b_finetuned")
tokenizer = AutoTokenizer.from_pretrained("ton-utilisateur/mistral7b_finetuned")
```

ğŸ”— **ModÃ¨le hÃ©bergÃ© sur :** [Hugging Face Model Hub](https://huggingface.co/ton-utilisateur/mistral7b_finetuned)

---

## ğŸ“Œ Prochaines Ã‰tapes

âœ… **Fine-tuning et Ã©valuation des modÃ¨les**<br>
âœ… **SÃ©lection du meilleur modÃ¨le (Mistral 7B Fine-Tuned)**<br>
âœ… **HÃ©bergement du modÃ¨le sur Hugging Face pour accÃ¨s public**<br>
ğŸ”œ **Ajout dâ€™une visualisation graphique des rÃ©sultats de lâ€™Ã©valuation**<br>
ğŸ”œ **DÃ©ploiement de lâ€™application sur Hugging Face Spaces ou un serveur cloud**<br>
ğŸ”œ **Ajout dâ€™un module dâ€™amÃ©lioration stylistique des poÃ¨mes gÃ©nÃ©rÃ©s**<br>

---

## ğŸ¤ Contribuer

Si vous souhaitez contribuer Ã  ce projet :

1. **Forkez le dÃ©pÃ´t**.
2. **Ajoutez vos amÃ©liorations** sur une nouvelle branche.
3. **Soumettez une Pull Request** avec une description dÃ©taillÃ©e de vos modifications.

Nâ€™hÃ©sitez pas Ã  poser vos questions ou signaler des problÃ¨mes via la section **Issues** sur GitHub.

**ğŸ”— Contact :** Pour toute question, contactez-moi directement via GitHub ou LinkedIn !

---

ğŸ”¥ **Merci dâ€™avoir suivi ce projet et bonne exploration de la gÃ©nÃ©ration de poÃ©sie avec lâ€™IA !** ğŸ”¥

