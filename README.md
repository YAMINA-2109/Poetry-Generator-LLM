# üöÄ Poetry Generator - Fine-Tuning et √âvaluation des Mod√®les LLM

Bienvenue dans ce projet de **g√©n√©ration de po√®mes** bas√© sur le **fine-tuning de mod√®les de langage**. Ce projet explore diff√©rentes architectures de mod√®les pour produire des po√®mes de haute qualit√© √† partir d'instructions donn√©es par l'utilisateur.

---

## üìå Objectifs du projet

- **Fine-tuner plusieurs mod√®les de langage** pour la g√©n√©ration de po√®mes.
- **Comparer les performances** des mod√®les en utilisant des m√©triques de qualit√© (BLEU, ROUGE, Cosine Similarity).
- **S√©lectionner le meilleur mod√®le** en fonction des performances obtenues.
- **D√©velopper une interface utilisateur interactive** permettant aux utilisateurs de g√©n√©rer des po√®mes en entrant un titre, un th√®me et des instructions sp√©cifiques.

---

## üõ†Ô∏è 1. Fine-Tuning et √âvaluation des Mod√®les

Nous avons test√© et compar√© **quatre mod√®les de langage** pour la g√©n√©ration de po√®mes :

1. **GPT-2** 
2. **LLaMA-3-8B** 
3. **Mistral 7B** 
4. **GPT-NeoX-20B**

üìå **Tous les notebooks de fine-tuning sont disponibles dans le dossier `notebooks/` du d√©p√¥t.**

### **üîç √âtapes du Fine-Tuning :**

1. **Pr√©paration des donn√©es** : S√©lection et pr√©traitement d‚Äôun dataset de po√®mes (`checkai/instruction-poems`).
2. **Fine-tuning sur GPU** : Entra√Ænement sur Google Colab et stockage sur Google Drive.
3. **√âvaluation des performances** : Calcul des scores BLEU, ROUGE et Cosine Similarity.
4. **Comparaison des r√©sultats** : S√©lection du mod√®le le plus performant pour l'application finale.

#### **üìä R√©sultats de l‚Äô√©valuation :**
## **1Ô∏è‚É£ Sur le dataset d'√©valuation (que le mod√®le a vu durant l'entra√Ænement) :** 

| Mod√®le | ROUGE-1 | ROUGE-2 | ROUGE-L | Cosine Similarity |
|--------|---------|---------|---------|------------------|
| GPT-2 Fine-Tuned | 0.8345 | 0.7342 | 0.8268 | 0.5457 |
| LLaMA-3-8B Fine-Tuned | 0.7895 | 0.6595 | 0.7802 | 0.6239 |
| GPT-NeoX-20B Fine-Tuned | 0.7002 | 0.4991 | 	0.6892 | 0.5245 |
| Mistral 7B Fine-Tuned | 0.7055 | 	0.5208 | 0.6934 | 0.6023 |

üìå **Analyse des r√©sultats :**  
- **GPT-2 Fine-Tuned** affiche les meilleurs scores ROUGE, indiquant une forte correspondance avec les textes d'entra√Ænement.  
- **LLaMA-3-8B Fine-Tuned** a la meilleure **similarit√© cosinus**, ce qui sugg√®re qu'il capture mieux la structure s√©mantique globale.  
- **Mistral 7B et GPT-NeoX-20B** ont des performances l√©g√®rement inf√©rieures mais restent comp√©titifs.

---

## **2Ô∏è‚É£ Sur le dataset de test (des donn√©es que le mod√®le n'a jamais vues) :** 

| Mod√®le | BLEU Score | ROUGE-1 | ROUGE-2 | ROUGE-L | Cosine Similarity |
|--------|-----------|---------|---------|---------|------------------|
| LLaMA-3-8B Fine-Tuned | 0.0138 |0.1531 | 0.0290 | 0.0970 | 0.1499 |
| GPT-NeoX-20B Fine-Tuned| 0.0167 | 0.1272 |  0.0332 |0.1024 | 0.1589|
| Mistral 7B Fine-Tuned | - | 0.0906 | 0.0178 | 0.0645 | 0.0866 |
| GPT-2 Fine-Tuned | errerurs lors du test|

üìå **Analyse des r√©sultats :**  
- **GPT-NeoX-20B Fine-Tuned** affiche le meilleur **score BLEU** et **ROUGE-2**, indiquant qu'il est plus pr√©cis dans la g√©n√©ration de s√©quences coh√©rentes.  
- **LLaMA-3-8B Fine-Tuned** obtient le meilleur **ROUGE-1**, ce qui signifie qu'il capte bien les mots-cl√©s des po√®mes de r√©f√©rence.  
- **Mistral 7B Fine-Tuned** a des scores plus faibles, sugg√©rant une moindre g√©n√©ralisation aux nouvelles donn√©es.


---

## üì∑ Interface d'√âvaluation

Nous avons d√©velopp√© une **interface intuitive avec Streamlit** pour permettre :

- La **g√©n√©ration de po√®mes** bas√©s sur un th√®me et des instructions sp√©cifiques.
- L‚Äô**√©valuation automatique des r√©sultats** √† l‚Äôaide de m√©triques NLP.
- L‚Äô**exportation des r√©sultats** au format CSV.
- L‚Äôobjectif principal de cette interface est d'√©valuer et de comparer les mod√®les afin de s√©lectionner le plus performant.
- Dans la prochaine √©tape, nous d√©velopperons une application adapt√©e aux utilisateurs finaux, int√©grant le mod√®le choisi.
  
Voici quelques images de notre interface ainsi que les r√©sultats obtenus lors de nos tests des mod√®les.
### **1Ô∏è‚É£ S√©lection du mod√®le et g√©n√©ration d'un po√®me**
![Interface compl√®te](images/interface_1_complete.PNG)

### **2Ô∏è‚É£ S√©lection du mod√®le et g√©n√©ration de po√®mes sur un ensemble de donn√©es (un dataset de plusieurs lignes)**
![Interface 2](images/interface_2.PNG)

### **3Ô∏è‚É£ Po√®me g√©n√©r√© avec Mistral 7B**
![Po√®me g√©n√©r√©](images/mistrale_generated_poeme_1.PNG)
![Po√®me score](images/mistrale_7b_1_poeme_results_scores.PNG)

### **4Ô∏è‚É£ Po√®me g√©n√©r√© avec LLaMA-3-8B**
![Po√®me g√©n√©r√©](images/poeme_llama_1.PNG)
![Po√®me score](images/1_poeme_score_llama_1.PNG)

### **5Ô∏è‚É£ Po√®me g√©n√©r√© avec GPT-2**
![Po√®me g√©n√©r√©](images/gpt_2_generated_poeme.PNG)

### **6Ô∏è‚É£ √âvaluation des scores BLEU et ROUGE pour LLaMA-3-8B sur un petit dataset de 50 lignes**
![R√©sultats d‚Äô√©valuation 1](images/resultats_llama_2.PNG)
![R√©sultats d‚Äô√©valuation 2](images/resultats_de_llama_1.PNG)

### **7Ô∏è‚É£ √âvaluation des scores BLEU et ROUGE pour Mistral 7B sur un petit dataset de 50 lignes**
![R√©sultats d‚Äô√©valuation](images/mistral_7b_resultats_2.PNG)
![R√©sultats d‚Äô√©valuation 2](images/miostral_7b_resultats_1.PNG)

### **8Ô∏è‚É£  √âvaluation des scores BLEU et ROUGE pour GPT-2 sur un petit dataset de 50 lignes**
![√âvaluation sur dataset](images/gpt_2_result_2.PNG)
![√âvaluation sur dataset](images/gpt2_scores_on_100_cols_1.PNG)

---

###**üéØ S√©lection du mod√®le final** 

D'apr√®s les r√©sultats obtenus dans les tableaux pr√©c√©dents, nous avons observ√© que les performances des mod√®les sont relativement proches, avec des r√©sultats satisfaisants sur le dataset d'√©valuation. Toutefois, sur le dataset de test, nous avons constat√© une diminution des performances. **GPT-NeoX-20B** et **LLaMA-3-8B** se sont r√©v√©l√©s √™tre les plus performants. 

Apr√®s plusieurs tests via notre interface (comme illustr√© par les images ci-dessous), nous avons exclu **GPT-2**, car il ne g√©n√©rait pas de po√®mes de mani√®re coh√©rente. De plus, **GPT-NeoX-20B** posait des probl√®mes de m√©moire, rendant son utilisation peu pratique. Finalement, le choix s'est fait entre **LLaMA-3-8B et Mistral 7B**, car ces deux mod√®les g√©n√©raient des po√®mes de qualit√© respectant bien les instructions et le format.

Voici un exemple des po√®mes g√©n√©r√©s par ces deux mod√®les :

üìå **Po√®me g√©n√©r√© par LLaMA-3-8B**

```
Don‚Äôt Bother the Earth Spirit
                      If you dig in the garden,
                    Remember the Earth Spirit
                      Is a restless thing,
                    It does not like to be bothered
                    With shovels and rakes.
                      If you plant a tree,
                    Don‚Äôt expect it to sit still,
                    The Earth Spirit likes to play
                    Hide-and-seek with its roots.
                      If you build a house,
                    Make sure it is deep,
                    The Earth Spirit likes to visit
                    And sometimes stay for a while.
                      If you walk in the woods,
                    Listen to the trees,
                    They will tell you where the Earth Spirit
                    Is hiding its treasures.
                      If you listen to the wind,
                    It will tell you where the Earth Spirit
                    Is going with its secrets.
                      If you follow the wind,
                    You will find the Earth Spirit
                    Dancing in the moonlight,
                    And if you follow the moon,
                    You will find the Earth Spirit
                    Singing its wild song.
                      Don‚Äôt bother the Earth Spirit.
```

üìå **Po√®me g√©n√©r√© par Mistral 7B**

```
Don‚Äôt bother the Earth Spirit, she‚Äôs busy,
                digging up roots, turning over stones,
                searching for the lost and the forgotten,
                the ones who wandered away from home.

                She‚Äôs the one who knows where the fairies live,
                the one who whispers to the wind,
                the one who sings to the moon,
                the one who dances with the stars.

                She‚Äôs the one who weaves the dreams,
                the one who paints the sunsets,
                the one who holds the secrets,
                the one who keeps the mysteries.

                Don‚Äôt bother the Earth Spirit, she‚Äôs busy,
                digging up roots, turning over stones,
                searching for the lost and the forgotten,
                the ones who wandered.
```
üìå **Apr√®s comparaison des r√©sultats et observation des po√®mes g√©n√©r√©s, nous avons d√©cid√© de choisir **Mistral 7B Fine-Tuned** comme mod√®le final pour notre application.** 

‚úÖ **Pourquoi Mistral 7B ?**  
- Il g√©n√®re des po√®mes plus fluides et artistiques, capturant mieux l'essence des th√®mes donn√©s.  
- Il respecte bien les instructions et la structure des po√®mes.  
- Il a une bonne gestion des prompts et une coh√©rence stylistique plus marqu√©e.  
- Il est plus l√©ger et moins gourmand en m√©moire que LLaMA-3-8B, ce qui facilite son d√©ploiement et son utilisation.  

  Ainsi, **Mistral 7B Fine-Tuned sera utilis√© dans notre application finale** pour g√©n√©rer des po√®mes en fonction des th√®mes et des instructions de l‚Äôutilisateur. üöÄ
---

## üöÄ 2. Acc√®s Public aux Mod√®les Fine-Tun√©s

üîó **Les mod√®les fine-tun√©s sont h√©berg√©s sur Hugging Face et peuvent √™tre t√©l√©charg√©s ici :**

- [LLaMA-3-8B Fine-Tuned](https://huggingface.co/IAyamina/llama3-8b_on_instruction_poems)
- [Mistral 7B Fine-Tuned](https://huggingface.co/IAyamina/mistral7b_on_instruction_poems)
- [GPT-2 Fine-Tuned](https://huggingface.co/IAyamina/gpt2_on_instruction_poems)
- [GPT-NeoX-20B Fine-Tuned](https://huggingface.co/IAyamina/gptneo20b_on_instruction_poems)

‚úÖ **Solution :**

- T√©l√©chargez le mod√®le directement depuis Hugging Face.
- Utilisez-le avec **Hugging Face Transformers** dans vos scripts Python.
- Ex√©cutez les notebooks associ√©s pour **r√©entra√Æner** le mod√®le et modifier les hyperparam√®tres si n√©cessaire.

üí° **Attention :**

- **Mistral 7B et LLaMA-3-8B n√©cessitent une cl√© d‚Äôacc√®s**. Vous devez **demander l‚Äôacc√®s** sur Hugging Face pour pouvoir les utiliser.

### **üîß √âtapes pour utiliser un mod√®le fine-tun√© :**

1Ô∏è‚É£ **Chargez le mod√®le dans votre script Python :**

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "IAYamina/mistral7b_on_instruction_poems"  # Remplacez par le mod√®le souhait√©
model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
```

2Ô∏è‚É£ **G√©n√©rez un po√®me avec le mod√®le :**

```python
def generate_poem(prompt):
    inputs = tokenizer(prompt, return_tensors="pt")
    output = model.generate(**inputs, max_length=100)
    return tokenizer.decode(output[0], skip_special_tokens=True)

print(generate_poem("Un po√®me sur l'automne"))
```

**Si n√©cessaire, entra√Ænez √† nouveau le mod√®le avec les notebooks disponibles.**

---

## üöÄ 3. Lancer l'Application et Tester les Po√®mes

üí° **Attention :**
- Notre code est con√ßu pour √™tre ex√©cut√© sur **Google Colab**.
- Vous devez **poss√©der une cl√© d'authentification pour `pyngrok`** si vous souhaitez d√©ployer l'application de la m√™me mani√®re.
- Tous le code n√©cessaires √† l'ex√©cution se trouvent dans `app.py`.

### **üîß √âtapes pour lancer l'application :**


## üöÄ 2. Lancer l'Application avec le Mod√®le Fine-Tun√©

### **üîß √âtapes pour lancer l'application :**

1Ô∏è‚É£ **Charger le mod√®le depuis Hugging Face** en utilisant les identifiants des mod√®les fine-tun√©s :
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "IAyamina/mistral7b_on_instruction_poems"
model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
```

2Ô∏è‚É£ **Installer les d√©pendances n√©cessaires (`streamlit`, `pyngrok`, etc.)** et s'assurer de disposer d'un **GPU A100** pour une ex√©cution optimale.

3Ô∏è‚É£ **Ex√©cuter `app.py` et lancer l'application Streamlit :**
```bash
!streamlit run app.py --server.port 8501
```

üìå **D√©tails techniques :**
- Le fine-tuning a √©t√© effectu√© sur **Google Colab** en utilisant `transformers`, `torch` et `datasets`.
- Tous les mod√®les sont accessibles via Hugging Face.
- Une connexion Internet stable et un GPU puissant sont recommand√©s pour des performances optimales.



---

## üìå Deuxi√®me √âtape :

‚úÖ **R√©alisation de l'Application Utilisateur**

Apr√®s avoir s√©lectionn√© le mod√®le le plus performant, l'√©tape suivante consiste √† **d√©velopper une interface conviviale** permettant aux utilisateurs de g√©n√©rer des po√®mes de mani√®re interactive. Cette application offrira plusieurs fonctionnalit√©s :

- Interface intuitive d√©velopp√©e avec **Streamlit**.
- G√©n√©ration instantan√©e de po√®mes √† partir d'un titre et d'instructions.
- Personnalisation du style et des th√®mes de po√®mes.
- √âvaluation en temps r√©el des po√®mes g√©n√©r√©s.

üìå **L'application sera h√©berg√©e en ligne pour une utilisation simplifi√©e par les utilisateurs.**



---


## üîÆ Perspectives et Am√©liorations

Pour am√©liorer les performances de notre mod√®le, plusieurs pistes d‚Äôam√©lioration sont envisag√©es :

- **R√©entra√Ænement sur un dataset plus large et diversifi√©** contenant des po√®mes de diff√©rents styles afin d‚Äôaugmenter la capacit√© du mod√®le √† capturer diverses structures po√©tiques.
- **Application du Reinforcement Fine-Tuning** avec l‚Äôalgorithme **PPO (Proximal Policy Optimization)** pour affiner encore davantage la qualit√© des po√®mes g√©n√©r√©s et am√©liorer leur coh√©rence stylistique et s√©mantique.
- **Optimisation des param√®tres du mod√®le** pour un meilleur compromis entre qualit√© des r√©sultats et rapidit√© d‚Äôex√©cution.

Ces am√©liorations permettront d‚Äôobtenir un mod√®le plus performant et capable de g√©n√©rer des po√®mes encore plus authentiques et personnalis√©s.

-----

## ü§ù Contribuer

Si vous souhaitez contribuer √† ce projet :

1. **Forkez le d√©p√¥t**.
2. **Ajoutez vos am√©liorations** sur une nouvelle branche.
3. **Soumettez une Pull Request** avec une description d√©taill√©e de vos modifications.

N‚Äôh√©sitez pas √† poser vos questions ou signaler des probl√®mes via la section **Issues** sur GitHub.

**üîó Contact :** Pour toute question, contactez-moi directement via GitHub ou LinkedIn !

---

üî• **Merci d‚Äôavoir suivi ce projet et bonne exploration de la g√©n√©ration de po√©sie avec l‚ÄôIA !** üî•

